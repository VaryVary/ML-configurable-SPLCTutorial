{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning specialization : LaTeX example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset_latex.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a list of the results of compilation of a latex document (if it is valid regarding the number of pages or not) and the options of the compilation associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the columns of the dataset in two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"valid\"])\n",
    "y = df[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X part is the one with the compilation options, or the data we always know. The y part is the one that has to be guessed with regard to the X part, usually called the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to split the rows of the dataset. One will be used to train the machine learning model, and the other will be used to verify how well the model is able to guess the label on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size=0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data all set up, here comes the machine learning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a decision tree classifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is now configured and is ready to be trained on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to predict, given a latex compilation configuration, the result of every latex compilation of the subject document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True, False,  True, False, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True, False, False, False, False,  True, False,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure how true the prediction is by using the testing set and the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677685950413223"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perk of decision tree : it is interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print it to vizualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def print_tree(clf, f_names, name):\n",
    "    \n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=f_names,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(name)\n",
    "    \n",
    "print_tree(clf, X_train.columns.values, \"tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a set of rules for which the compilation will give a valid result (according to the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS_SCRIPTSIZE <= 0.5 & cserver_size <= 0.8499999940395355 & bref_size <= 0.949999988079071\n",
      "JS_SCRIPTSIZE <= 0.5 & cserver_size <= 0.8499999940395355 & bref_size > 0.949999988079071 & cserver_size <= 0.75\n",
      "JS_SCRIPTSIZE <= 0.5 & cserver_size <= 0.8499999940395355 & bref_size > 0.949999988079071 & cserver_size > 0.75\n",
      "JS_SCRIPTSIZE <= 0.5 & cserver_size > 0.8499999940395355 & PL_FOOTNOTE <= 0.5 & vspace_bib <= 4.549999952316284\n",
      "JS_SCRIPTSIZE <= 0.5 & cserver_size > 0.8499999940395355 & PL_FOOTNOTE > 0.5 & bref_size <= 0.949999988079071\n",
      "JS_SCRIPTSIZE > 0.5 & cserver_size <= 0.75 & PL_FOOTNOTE <= 0.5 & PARAGRAPH_ACK <= 0.5\n",
      "JS_SCRIPTSIZE > 0.5 & cserver_size <= 0.75 & PL_FOOTNOTE > 0.5 & bref_size <= 0.8499999940395355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "\n",
    "def tree_to_rules_valid(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    #print (\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, previous_rules):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], previous_rules+[name + \" <= \" + str(threshold)])\n",
    "            #print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], previous_rules+[name + \" > \" + str(threshold)])\n",
    "        else:\n",
    "            if tree_.value[node][0][0] < tree_.value[node][0][1]:\n",
    "                #print(\" & \".join(previous_rules) + \" ---> \" + str(tree_.value[node]))\n",
    "                print(\" & \".join(previous_rules))\n",
    "\n",
    "\n",
    "    recurse(0, [])\n",
    "    \n",
    "tree_to_rules_valid(clf, X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a good metric but can hide some flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Predicted True   Predicted False\n",
      "Actual True    71 (TP)          4 (FN)\n",
      "Actual False   7 (FP)          39 (TN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, clf.predict(X_test)).ravel()\n",
    "\n",
    "print(\"            \",\"Predicted True\",\"  Predicted False\")\n",
    "print(\"Actual True   \",tp,\"(TP)         \", fn,\"(FN)\")\n",
    "print(\"Actual False  \",fp,\"(FP)         \", tn,\"(TN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we learn from the confusion matrix : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "recall = TP / (TP + FN) -> Flexibility\n",
    "\n",
    "precision = TP / (TP + FP) -> Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it again, make the parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Parameters\n",
    "\n",
    "test_size=0.3\n",
    "\n",
    "#Decision tree classifier parameters\n",
    "#More details here : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "hyperparams = {\n",
    "    \"criterion\":\"gini\",\n",
    "    \"splitter\":\"best\",\n",
    "    \"max_features\":None,\n",
    "    \"max_depth\":None,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":1,\n",
    "    \"min_weight_fraction_leaf\":0.,\n",
    "    \"max_leaf_nodes\":None,\n",
    "    \"class_weight\":None,\n",
    "    \"random_state\":None,\n",
    "    \"min_impurity_decrease\":1e-7,\n",
    "    \"presort\":False\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(**hyperparams)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning specialization : LaTeX example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK</th>\n",
       "      <th>BIB</th>\n",
       "      <th>BOLD_ACK</th>\n",
       "      <th>BREF</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>JS_FOOTNOTESIZE</th>\n",
       "      <th>JS_SCRIPTSIZE</th>\n",
       "      <th>JS_STYLE</th>\n",
       "      <th>JS_TINY</th>\n",
       "      <th>LONG_ACK</th>\n",
       "      <th>LONG_AFFILIATION</th>\n",
       "      <th>PARAGRAPH_ACK</th>\n",
       "      <th>PL_FOOTNOTE</th>\n",
       "      <th>VARY_LATEX</th>\n",
       "      <th>bref_size</th>\n",
       "      <th>cserver_size</th>\n",
       "      <th>vspace_bib</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACK   BIB  BOLD_ACK  BREF  EMAIL  JS_FOOTNOTESIZE  JS_SCRIPTSIZE  \\\n",
       "0   True  True     False  True  False            False           True   \n",
       "1  False  True     False  True  False            False           True   \n",
       "2  False  True     False  True  False            False          False   \n",
       "3   True  True      True  True  False            False          False   \n",
       "4   True  True     False  True  False            False           True   \n",
       "\n",
       "   JS_STYLE  JS_TINY  LONG_ACK  LONG_AFFILIATION  PARAGRAPH_ACK  PL_FOOTNOTE  \\\n",
       "0      True    False     False             False           True         True   \n",
       "1      True    False     False             False          False         True   \n",
       "2      True     True     False             False          False        False   \n",
       "3      True     True      True             False          False         True   \n",
       "4      True    False      True             False           True        False   \n",
       "\n",
       "   VARY_LATEX  bref_size  cserver_size  vspace_bib  valid  \n",
       "0        True        1.0           0.9         2.7  False  \n",
       "1        True        0.9           0.6         4.7  False  \n",
       "2        True        0.7           0.9         4.6  False  \n",
       "3        True        0.8           0.6         2.3  False  \n",
       "4        True        0.7           0.8         1.7  False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset_latex.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a list of the results of compilation of a latex document (if it is valid regarding the number of pages or not) and the options of the compilation associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the columns of the dataset in two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"valid\"])\n",
    "y = df[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X part is the one with the compilation options, or the data we always know. The y part is the one that has to be guessed with regard to the X part, usually called the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to split the rows of the dataset. One will be used to train the machine learning model, and the other will be used to verify how well the model is able to guess the label on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size=0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data all set up, here comes the machine learning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a decision tree classifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is now configured and is ready to be trained on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to predict, given a latex compilation configuration, the result of every latex compilation of the subject document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True, False, False,  True, False, False, False,  True, False,\n",
       "        True,  True,  True,  True, False,  True, False,  True, False,\n",
       "       False, False,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "       False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False,  True,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure how true the prediction is by using the testing set and the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perk of decision tree : it is interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print it to vizualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def print_tree(clf, f_names, name):\n",
    "    \n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=f_names,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(name)\n",
    "    \n",
    "print_tree(clf, X_train.columns.values, \"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"500\"\n",
       "            src=\"tree.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f466951da58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame, display\n",
    "filepath = \"tree.pdf\"\n",
    "IFrame(filepath, width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a set of rules for which the compilation will give a valid result (according to the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS_TINY <= 0.5 & cserver_size <= 0.6499999761581421 & PL_FOOTNOTE <= 0.5 & bref_size <= 0.949999988079071\n",
      "JS_TINY <= 0.5 & cserver_size <= 0.6499999761581421 & PL_FOOTNOTE <= 0.5 & bref_size > 0.949999988079071\n",
      "JS_TINY <= 0.5 & cserver_size <= 0.6499999761581421 & PL_FOOTNOTE > 0.5 & PARAGRAPH_ACK <= 0.5\n",
      "JS_TINY > 0.5 & cserver_size <= 0.8500000238418579 & bref_size <= 0.949999988079071 & LONG_ACK <= 0.5\n",
      "JS_TINY > 0.5 & cserver_size <= 0.8500000238418579 & bref_size <= 0.949999988079071 & LONG_ACK > 0.5\n",
      "JS_TINY > 0.5 & cserver_size <= 0.8500000238418579 & bref_size > 0.949999988079071 & PL_FOOTNOTE <= 0.5\n",
      "JS_TINY > 0.5 & cserver_size <= 0.8500000238418579 & bref_size > 0.949999988079071 & PL_FOOTNOTE > 0.5\n",
      "JS_TINY > 0.5 & cserver_size > 0.8500000238418579 & PL_FOOTNOTE <= 0.5 & vspace_bib <= 4.5\n",
      "JS_TINY > 0.5 & cserver_size > 0.8500000238418579 & PL_FOOTNOTE <= 0.5 & vspace_bib > 4.5\n",
      "JS_TINY > 0.5 & cserver_size > 0.8500000238418579 & PL_FOOTNOTE > 0.5 & bref_size <= 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "\n",
    "def tree_to_rules_valid(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    #print (\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, previous_rules):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #print (\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], previous_rules+[name + \" <= \" + str(threshold)])\n",
    "            #print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], previous_rules+[name + \" > \" + str(threshold)])\n",
    "        else:\n",
    "            if tree_.value[node][0][0] < tree_.value[node][0][1]:\n",
    "                #print(\" & \".join(previous_rules) + \" ---> \" + str(tree_.value[node]))\n",
    "                print(\" & \".join(previous_rules))\n",
    "\n",
    "\n",
    "    recurse(0, [])\n",
    "    \n",
    "tree_to_rules_valid(clf, X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a good metric but can hide some flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Predicted True   Predicted False\n",
      "Actual True    66 (TP)          6 (FN)\n",
      "Actual False   5 (FP)          44 (TN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, clf.predict(X_test)).ravel()\n",
    "\n",
    "print(\"            \",\"Predicted True\",\"  Predicted False\")\n",
    "print(\"Actual True   \",tp,\"(TP)         \", fn,\"(FN)\")\n",
    "print(\"Actual False  \",fp,\"(FP)         \", tn,\"(TN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we learn from the confusion matrix : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "recall = TP / (TP + FN) -> Flexibility\n",
    "\n",
    "precision = TP / (TP + FP) -> Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it again, make the parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099173553719008"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Parameters\n",
    "\n",
    "test_size=0.3\n",
    "\n",
    "#Decision tree classifier parameters\n",
    "#More details here : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "hyperparams = {\n",
    "    \"criterion\":\"gini\",\n",
    "    \"splitter\":\"best\",\n",
    "    \"max_features\":None,\n",
    "    \"max_depth\":2,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":1,\n",
    "    \"min_weight_fraction_leaf\":0.,\n",
    "    \"max_leaf_nodes\":None,\n",
    "    \"class_weight\":None,\n",
    "    \"random_state\":None,\n",
    "    \"min_impurity_decrease\":1e-7\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(**hyperparams)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
